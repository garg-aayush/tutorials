# Post-training and Reinforcement Learning approaches

## Books
- [RLHF book by Nathan Lambert](https://rlhfbook.com/] ): A short introduction to RLHF and post-training focused on language models

## Blogs
- [Introduction to LLMs post training](https://tokens-for-thoughts.notion.site/post-training-101): Guide to understanding the basics of LLM post-training


## PPO Understanding Resources
- [X] [Umar Jamil's video on RLHF and PPO](https://www.youtube.com/watch?v=qGyFrqc34yc): A great and a must-watch video on RLHF and PPO.
- Papers:
    - [ ] [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)
    - [ ] [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155): InstructGPT paper (PPO with KL penalty to mitigate reward hacking)
    - [ ] [Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477)
