{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Simple RoPE Implementation:\n",
        "\n",
        "- Resources:\n",
        "    - [Llama explained video by Umar Jamil](https://www.youtube.com/watch?v=Mn_9W1nCFLo): Refer to RoPE section starting at 24:30 timestamp \n",
        "    - [Efficient NLP's RoPE explanation](https://www.youtube.com/watch?v=o29P0Kpobz0)\n",
        "    - [RoPE paper](https://arxiv.org/abs/2104.09864)\n",
        "    - [Transformers RoPE implementation](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py#L73)\n",
        "    - [ROPE Notes](https://github.com/garg-aayush/building-from-scratch/blob/main/gpt-2/notes/RoPE.md) \n",
        "\n",
        "> Taken from: https://github.com/garg-aayush/building-from-scratch/blob/main/gpt-2/play-nbs/rope.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RoPE module that rotates query/key feature pairs by position-dependent angles\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim, max_seq_len=2048):\n",
        "        super().__init__()\n",
        "        # dim: per-head size; max_seq_len: how many positions to precompute\n",
        "        assert dim % 2 == 0, f\"RotaryEmbedding requires even head_dim, got {dim}\"\n",
        "        self.dim = dim\n",
        "        self.max_seq_len_cached = max_seq_len\n",
        "        # inverse frequencies for each pair\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer(\"inv_freq\", inv_freq)  # keep on device, not trainable\n",
        "        # positions [0..max_seq_len-1]\n",
        "        t = torch.arange(self.max_seq_len_cached, device=self.inv_freq.device).type_as(self.inv_freq)\n",
        "        # outer product â†’ angles per (position, pair)\n",
        "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
        "        # duplicate to match two halves of the head dimension\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        # cache sin/cos for all positions/pairs, shaped [1,1,T,D]\n",
        "        self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :])\n",
        "        self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [bs, num_heads, seq_len, head_dim];\n",
        "        seq_len = x.shape[2]\n",
        "        cos = self.cos_cached[:, :, :seq_len, :].to(dtype=x.dtype, device=x.device)\n",
        "        sin = self.sin_cached[:, :, :seq_len, :].to(dtype=x.dtype, device=x.device)\n",
        "\n",
        "        def rotate_half(x_):\n",
        "            # rotate by swapping halves and negating the second\n",
        "            x1 = x_[..., : self.dim // 2]\n",
        "            x2 = x_[..., self.dim // 2 :]\n",
        "            # [-x2, x1]: a 90-degree rotation in each 2D feature pair\n",
        "            return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "        # standard RoPE: apply rotation with per-position cos/sin\n",
        "        return x * cos + rotate_half(x) * sin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# --- Device Setup ---\n",
        "device = \"cpu\"\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "print(f\"--- Using device: {device} ---\")\n",
        "\n",
        "# --- Hyperparameters for testing ---\n",
        "batch_size = 2\n",
        "num_heads = 4\n",
        "seq_len = 16\n",
        "head_dim = 32\n",
        "\n",
        "# --- Test Initialization ---\n",
        "print(\"--- Initializing Test ---\")\n",
        "# Instantiate the RoPE module and move it to the selected device\n",
        "rope = RotaryEmbedding(dim=head_dim, max_seq_len=seq_len).to(device)\n",
        "# Create a random input tensor on the selected device\n",
        "x = torch.randn(batch_size, num_heads, seq_len, head_dim).to(device)\n",
        "print(\"Test setup complete.\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "# --- Apply RoPE ---\n",
        "y = rope(x)\n",
        "\n",
        "# --- Test 1: Shape check ---\n",
        "print(\"--- Test 1: Shape Check ---\")\n",
        "print(f\"Input shape:  {x.shape}\")\n",
        "print(f\"Output shape: {y.shape}\")\n",
        "assert x.shape == y.shape, \"Shape mismatch after RoPE application\"\n",
        "print(\"âœ… Shape check passed.\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "# --- Test 2: Norm preservation check ---\n",
        "print(\"--- Test 2: Norm Preservation Check ---\")\n",
        "# RoPE is a rotation, so it should preserve the L2 norm of the vectors.\n",
        "norm_x = torch.linalg.norm(x, dim=-1)\n",
        "norm_y = torch.linalg.norm(y, dim=-1)\n",
        "# Check if norms are close with a small tolerance\n",
        "assert torch.allclose(norm_x, norm_y, atol=1e-6), \"Norm preservation failed\"\n",
        "print(\"âœ… Norm preservation check passed.\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "# --- Test 3: Relative position property ---\n",
        "print(\"--- Test 3: Relative Position Property Check ---\")\n",
        "# The dot product between two rotated vectors should only depend on their relative position.\n",
        "# Let's check if dot product of q at pos m and k at pos n is the same as\n",
        "# that of q at pos m+d and k at pos n+d for some distance d.\n",
        "\n",
        "# Pick two positions m, n and a shift d\n",
        "m, n = 2, 8\n",
        "d = 4\n",
        "assert m + d < seq_len and n + d < seq_len, \"Test positions are out of bounds\"\n",
        "\n",
        "# Get the rotated vectors from the output y at original positions\n",
        "q_m_rot = y[:, :, m, :]\n",
        "k_n_rot = y[:, :, n, :]\n",
        "# Compute their dot product\n",
        "dot_product1 = torch.sum(q_m_rot * k_n_rot, dim=-1)\n",
        "\n",
        "# To test the relative property, we rotate the *same* original vectors\n",
        "# but as if they were at positions m+d and n+d.\n",
        "# We create a new input tensor for rope where only these positions are non-zero.\n",
        "x2 = torch.zeros_like(x).to(device)\n",
        "x2[:, :, m+d, :] = x[:, :, m, :] # original q is now at m+d\n",
        "x2[:, :, n+d, :] = x[:, :, n, :] # original k is now at n+d\n",
        "\n",
        "# Apply RoPE to this new sparse tensor\n",
        "y2 = rope(x2)\n",
        "q_md_rot = y2[:, :, m+d, :]\n",
        "k_nd_rot = y2[:, :, n+d, :]\n",
        "# Compute the dot product of the newly rotated vectors\n",
        "dot_product2 = torch.sum(q_md_rot * k_nd_rot, dim=-1)\n",
        "\n",
        "# The dot products should be equal because the relative distance (n-m) is the same as ((n+d)-(m+d)).\n",
        "assert torch.allclose(dot_product1, dot_product2, atol=1e-6), \"Relative position property failed\"\n",
        "print(\"âœ… Relative position property check passed.\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "print(\"\\nðŸŽ‰ All tests passed successfully! ðŸŽ‰\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "diffusers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
